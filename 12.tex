\section*{Lecture 12}
We will recall the setup and will now introduce a fourth tool in induction on scale to prove the full decoupling theorem by Bourgain and Demeter.

Let $P$ denote the paraboloid in $\R^n$, and let $\theta$ be the $R^{-1/2}$ caps of decomposition of $\Omega$. And we have the following estimate:
\begin{theorem}[Bourgain and Demeter]
    $f$ has the Fourier support $\widehat{f}$ in $\Omega$, then we have, for $2\leq p\leq\frac{2(n+1)}{n-1}$,
    \begin{equation*}
        \|f\|_{L^p}\lesssim R^\epsilon\left(\sum\|f_\theta\|_{L^p}^2 \right)^{1/2}
    \end{equation*}
    In other words, the decoupling constant $D_{p,n}\lesssim R^\epsilon$.
\end{theorem}
We now define a new notation that encompasses all the information that we have gathered to pass from one scale to another.

\begin{equation*}
    M_{p,q}(r,\sigma)={Avg}_{B_r\subset B_R}\prod_{j=1}^n\left(\sum_{\theta\subset\Omega_j}\|f_{j,\theta}\|_{L_{avg}^q(B_r)}^2 \right)^{\frac{1}{2}\frac{1}{n}p}
\end{equation*}
In the Fourier space, we disect $\Omega_j$ into $\sigma^{-1}$ caps of $\theta$; then we come back to the physical space and take $\sigma=r^{1/2}$ to disect the physical space, and divide $B_R$ into finitely overlapping unions of balls $B_r$, and note $f_{j,\theta}$ is roughly constant on $r^{1/2}\times r$-tubes pointing in the normal direction of $\theta$.

We consider two important cases. The first one is if we take $\sigma=r=1$,
then we would have
\begin{equation*}
    M_{p,q}(1,1)=Avg_{B_1\subset B_R}\prod_{j=1}^n\|f_j\|_{L_a^q(B_1)}^{\frac{1}{n}p}=\avint_{B_R}\prod_{j=1}^n|f_j|^{\frac{p}{n}}
\end{equation*}

This is because $B_1$ is small enough to invoke the locally constant property, we have $|f_j|$ being constant on $B_1$. Hence we have
\begin{equation*}
    \prod_{j=1}^n\|f_j\|_{L_a^q(B_R)}^{\frac{1}{n}p}\sim\prod |f_j|^{\frac{1}{n}p}\sim\avint_{B_1}\prod_{j=1}^n|f_j|^{\frac{1}{n}p}
\end{equation*}
Let's recall the multilinear decoupling inequality:
\begin{equation*}
    \left\|\prod_{j=1}^n|f_j|^{1/n} \right\|_{L_{avg}^p(B_R)}\lesssim R^\epsilon\prod_{j=1}^n\left(\sum_{\theta\subset\Omega_j}\|f_{j,\theta}\|_{L^p(\omega B_R)}^{1/n} \right)^{\frac{1}{2}\frac{1}{n}}
\end{equation*}
This means $M_{p,q}(1,1)$ is the LHS of the multilinear decoupling inequality (raised to the $p$-th power), then now let's see the RHS. Our second example would be to take $r=R$, and $\sigma=R^{1/2}$, then we would have
\begin{equation*}
    M_{p,q}(R,R^{1/2})=\prod_{j=1}^n\left(\sum_{\theta:R^{-1/2}caps}\|f_{j,\theta}\|_{L_a^q(B_R)}^2 \right)^{\frac{1}{n}\frac{1}{2}p}
\end{equation*}
The above equation is the RHS of the multilinear decoupling inequality.

Now it is clear what we have to do, that is to increase $r,\sigma$ to go from $M_{p,q}(1,1)$ to $M_{p,q}(R, R^{1/2})$.

We now introduce and prove the main tools that prove the full decoupling theorem. The first one concerns with local orthoganality and it says the finer caps are actually worse in approximating.
\begin{lemma}[Orthoganlity]
    If $\sigma\leq r$, then we have
    \begin{equation*}
        M_{p,2}(r,\sigma)\lesssim M_{p,2}(r,r)
    \end{equation*}
\end{lemma}
\begin{proof}
    We are fixing $q=2$, hence we have
    \begin{equation*}
        M_{p,2}(r,\sigma)=Avg_{B_r\subset B_R}\prod_{j=1}^n\left(\sum_{\tau\subset\Omega_j}\|f_{j,\tau}\|_{L^2}^2\right)^{\frac{1}{n}\frac{1}{2}p}
    \end{equation*}
    Then we decompose each $\tau$ into even smaller $r^{-1}$ caps, given $\sigma\leq r$, then by orthoganlity inequality, we have
    \begin{equation*}
        \|f_{j,\tau}\|_{L^2}\lesssim \left(\sum_{\theta\subset\tau}\|f_{j,\theta}\|_{L^2}^2 \right)^{1/2}
    \end{equation*}
    Hence combining, we have
    \begin{equation*}
        M_{p,2}(r,\sigma)\lesssim Avg_{B_r\subset B_R}\prod_{j=1}^n\left(\sum_{r\subset\Omega_j}\|f_{j,\theta}\|_{L^2}^2 \right)^{\frac{1}{2}\frac{1}{n}p}=M_{p,2}(r,r)
    \end{equation*}
\end{proof}
\qed


Now we prove a result using multilinear Kakeya.
\begin{lemma}[MK]
    For $p=\frac{2n}{n-1}$, if $r\leq R^{1/2}$, then we have the following:
    \begin{equation*}
        M_{p,2}(r,r)\lesssim r^\epsilon M_{p,2}(r^2, r)
    \end{equation*}
\end{lemma}
\begin{remark}
    Let's interpret this lemma. This states the if the dissection of the Fourier space is small enough, we then would have it bounded up by not so big value of a a really large ball?
\end{remark}
To prove this, we first realize for $p=\frac{2n}{n-1}$, the RHS exponent becomes $\frac{1}{n-1}$ which is the multilinear Kakeya exponent. Recall we have, if we have a weighted characterstic function $g_j$ such that
\begin{equation*}
    g_j=\sum_aT_{j,a}W_{j,a}
\end{equation*}
where $W_{j,a}\geq 0$, $T_{j,a}$ is a tube close to $x_j$ for all $a$.
We can invoke the multilinear Kakeya in this case.
\begin{equation*}
    \int_{Q_s}\prod_{j=1}^n|g_j|^{\frac{1}{n-1}}\lesssim S^\epsilon\prod_{j=1}^n\left(\int_{Q_s}|g_j| \right)^{\frac{1}{n-1}}
\end{equation*}
In this case, if we have $g_j=\sum_\theta\|f_{j,\theta}\|_{L^2(B_r)}^2$, for $x\in B_r$, then $g_j$ is a characteristic function with tubes of size $r\times r^2$ pointing near the normal direction of $\Sigma_j$ with positive weights.
We thus have
\begin{align*}
    M_{p,2}(r,r)&=Avg_{B_{r^2}\subset B_R}Avg_{B_r\subset B_{r^2}}\prod_{j=1}^n\left(\sum_\theta\|f_{j,\theta}\|_{L^2(B_r)}^2 \right)^{\frac{p}{2n}}\\
    &\sim Avg_{B_{r^2}\subset B_R}\avint\prod_{j=1}^n|g_j|^{\frac{1}{n-1}}\\
    &\lesssim Avg_{B_{r^2}\subset B_R}r^\epsilon\prod_{j=1}^n\left(\avint|g_j| \right)^{\frac{1}{n-1}}\\
    &\lesssim r^\epsilon Avg_{B_{r^2}\subset B_R}\prod_{j=1}^n\left(\sum_{\theta}\|f_{j,\theta}\|_{L^2(B_{r^2})}^2 \right)^{\frac{1}{n-1}}\\
    &=r^\epsilon M_{p,2}(r^2, r)
\end{align*}
\qed

This completes our proof.

We make a note on the difference between full decoupling theorem and the critical exponent of $p=\frac{2n}{n-1}$, if $p>\frac{2n}{n-1}$, then we can prove an estimate of the form
\begin{equation*}
    M_{p,2}(r,r)\lesssim r^\alpha M_{p,2}(r^2,r)
\end{equation*}
This makes it hard to increase the scale and to go from $r$ to $R$, as we introduce a nontrivial power of $r^\alpha$ each time. This means we will need a stronger multilinear decoupling theorem stated as follows:
\begin{theorem}[MK2]
    If $r\leq R^{1/2}$, if we have $\frac{(n-1)p}{n}\geq 2$, then we have
    then we have
    \begin{equation*}
        M_{p,\frac{(n-1)p}{n}}(r,r)\lesssim r^\epsilon M_{p,\frac{(n-1)p}{n}}(r^2,r)
    \end{equation*}
\end{theorem}
\begin{remark}
    Notice once we have this estimate, we are able to mimic what we did for the case $p=\frac{2n}{n-1}$.
\end{remark}
\begin{proof}
We will prove this now. Notice if we further separate the $\theta$'s based on their contribution, we get
\begin{equation*}
    \Theta_{j,\lambda}=\{\theta: \frac{\lambda}{2}\leq\|f_{j,\theta}\|_{L^q}\leq 2\lambda\}
\end{equation*}
Then if we define $\lambda_j^+=\max\{\lambda: |\Theta_{j,\lambda}|\geq 1\}$, this quantity records the largest quantity that we have for each $j$ that we can still ensure some value of $\|f_{j,\theta}\|_{L^q}$ lands in there. And we observe, if a $lambda$ is too small compared to this $\lambda_j^+$, then it doesn't contribute much to the overall quantity. We have
\begin{equation*}
    \sum_{\lambda\leq r^{-100n}\lambda_j^+, \theta\in\Theta_{j,\lambda}}\|f_{j,\theta}\|_{L^q}\ll \sum_{\theta\subset\Theta_{j,\lambda_j^+}}\|f_{j,\theta}\|_{L^q}
\end{equation*}
This inequality gives that compared to the largest $\lambda_j^+$ (which capture many true values) the ones that have very tiny $\lambda$ does not count too much. Hence we have
\begin{equation*}
    \sum_\theta\|f_{j,\theta}\|_{L^q(B_{r^2})}^q=\sum_\lambda\sum_{\theta\in\Theta_{j,\lambda}}\|f_{j,\theta}\|_{L^q(B_{r^2})}^q\sim \sum_{r^{-100n}\lambda_j^+\leq\lambda\leq\lambda_j^+}\sum_{\theta\in\Theta_{j,\lambda}}\|f_{j,\theta}\|_{L^q(B_{r^2})}^q
\end{equation*}
Hence to prove MK2, by definition of $M$, $\theta$ are $r^{-1}$ caps, we have on the LHS,
\begin{equation*}
    \Avg_{B_{r^2}\subset B_R}\Avg_{B_r\subset B_{r^2}}\prod_{j=1}^n\left(\sum_{\theta}\|f_{j,\theta}\|_{L^q}^2 \right)^{\frac{1}{2np}}
\end{equation*}
Hence for inside of the averaging sign, we have
\begin{align*}
    \Avg_{B_r\subset B_{r^2}}\prod_{j=1}^n\left(\sum_\theta\|f_{j,\theta}\|_{L^q}^2 \right)^{\frac{1}{2np}}&\leq (\log{r})^{O(1)}\max_{\lambda_1, ..., \lambda_n}\left[\avint_{B_{r^2}}\prod\left(\sum_{\theta\subset\Theta_{j,\lambda_j}}\|f_{j,\theta}\|_{L^q(B_r)}^2\right)^{\frac{1}{2np}} \right]\\
    &\leq(\log{r})^{O(1)}r^\epsilon\max_{\lambda_1, ..., \lambda_n}\prod\left(\sum_{\theta\in\Theta_{j,\lambda_j}}\|f_{j,\theta}\|_{L_a^q(B_{r^2})}^2 \right)^{\frac{1}{2np}}
\end{align*}



\end{proof}

\begin{lemma}
    If $p=\frac{2(n+1)}{n-1}$, then we have
    \begin{equation*}
        M_{p,2}(1,1)\lesssim R^{O(\delta)}M_{p,2}(r^2,r)^{1/2}M_{p,p}(r^2,r)^{1/2}
    \end{equation*}
\end{lemma}
Notice we have two terms on the RHS, hence we now introduce the two Holder inequalities that we need (we will just take them for granted, they are not hard to prove).
If we have $q_1\leq q_2$, then
\begin{equation*}
    M_{p,q_1}(r,\sigma)\leq M_{p,q_2}(r,\sigma)
\end{equation*}
Next we have, if $\|f\|_{L^q}\leq\|f\|_{L^{q_1}}^{\alpha_1}\|f\|_{L^{q_2}}^{\alpha_2}$, then we have
\begin{equation*}
    M_{p,q}(r,\sigma)\leq M_{p,q_1}^{\alpha_1}(r, \sigma)M_{p,q_2}^{\alpha_2}(r,\sigma)
\end{equation*}
\begin{proof}[of lemma above]
    We start with the LHS of multilinear decoupling, which is $M_{p,2}(1,1)$,
    \begin{align*}
        M_{p,2}(1,1)&\lesssim R^{O(\delta)}M_{p,2}(r,1)\\
        & O \lesssim R^{O(\delta)}M_{p,2}(r,r)\\
        & H \lesssim R^{O(\delta)}M_{p,\frac{(n-1)p}{n}}(r,r)\\
        & MK2 \lesssim R^{O(\delta)}M_{p,\frac{(n-1)p}{n}}(r^2,r)\\
        & H_2 \lesssim R^{O(\delta)} M_{p,2}(r^2,r)^{1/2}M_{p,p}(r^2,r)^{1/2}
    \end{align*}
\end{proof}
\qed

To justify $H_2$, the last line, we should have to show $f$ satisfies:
\begin{equation*}
    \|f\|_{L^\frac{2n+2}{n}}\lesssim \|f\|_{L^2}^{1/2}\|f\|_{L^\frac{2n+2}{n-1}}^{1/2}
\end{equation*}
We thus start from the LHS:
\begin{equation*}
    \|f\|_{L^\frac{2n+2}{n}}^\frac{2n+2}{n}=\int|f|\cdot|f|^{\frac{n+2}{n}}\leq\|f\|_{L^2}\|f^\frac{n+2}{n}\|_{L^2}
\end{equation*}
The first term, when raised to the $\frac{n}{2b+2}<1/2$, is bounded by $\|f\|_{L^2}^{1/2}$. And the second term, we have
\begin{equation*}
    \left(\int|f|^{\frac{2n+4}{n}}\right)^{\frac{n}{2n+2}\cdot\frac{1}{2}}=\left(\int|f|^{\frac{2n+2}{n}}|f|^\frac{2}{n}\right)^{\frac{n}{2n+2}\cdot\frac{1}{2}} \lesssim \|f\|_{L^p}^{1/2}
\end{equation*}
Thus justified the last step. Now we would like to examine what we have:
\begin{equation*}
    M_{p,2}(1,1)\lesssim R^{O(\delta)}M_{p,2}(r^2,r)^{1/2}M_{p,p}(r^2,r)^{1/2}
\end{equation*}
Notice the $M_{p,2}(r^2,r)$ term is an immediate term in our above process, hence to can keep dissecting it i.e. we can have
\begin{equation*}
    M_{p,2}(r^2,r)^{1/2}\lesssim M_{p,2}(r^2, r^2)^{1/2}\lesssim M_{p,\frac{2n+2}{n}}(r^2, r^2)^{1/2}\lesssim ...\lesssim M_{p,2}(r^4, r^2)^{1/4}M_{p,p}(r^4, r^2)^{1/4}
\end{equation*}
Hence we observe, the $M_{p,2}(r^2,r)$ term gets smaller and smaller, and we now analyze $M_{p,p}(r^2,r)$ term. Our goal is to bound $M_{p,p}(r^2, r)$ by $D(R/r^2)^pM_{p,p}(R, R^{1/2})$.
\begin{proposition}
    By parallel decoupling and parabolic rescaling, we have the following
    \begin{equation*}
        M_{p,p}(r,\sigma)\leq D(R/\sigma^2)^pM_{p,p}(R, R^{1/2})
    \end{equation*}
\end{proposition}
\begin{proof} Assume $\tau$ are $\sigma^{-1}$ caps, we have
    \begin{equation*}
        M_{p,p}(r,\sigma)=\Avg_{B_r\subset B_R}\prod_{j=1}^n\left(\sum_\tau\|f_{j,\tau}\|_{L^p} \right)^{\frac{p}{2n}}
    \end{equation*}
    We will write $\Avg$ as an average integral for simplicity.
    \begin{align*}
        M_{p,p}(r,\sigma)&=\avint_{B_R}\prod_{j=1}^n\left(\sum_\tau\|f_{j,\tau}\|_{L^p(B_r)}^2 \right)^{\frac{p}{2n}}\\
        &\leq \prod_{j=1}^n\left(\avint_{B_R}\left(\sum_\tau\|f_{j,\tau}\|_{L^p(B_r)}^2 \right)^{p/2}\right)^{1/n}\\
        &\leq \prod_{j=1}^n\left(\sum_\tau\avint_{B_R}\|f_{j,\tau}\|_{L^p(B_r)}^2 \right)^{p/2n}\\
        &=\prod_{j=1}^n\left(\sum_\tau\|f_{j,\tau}\|_{L^p(B_R)}^2 \right)^{p/2n}
    \end{align*}
\end{proof}
Then we want to further decompose $\tau$ into smaller caps of size $R^{-1/2}$ of $\theta$'s, and we would get
\begin{equation*}
    \|f_{j,\tau}\|_{L^p}\leq D_p(\tau=\bigsqcup\theta)\left(\sum\|f_{j,\theta}\|_{L^p}^2 \right)^{1/2}
\end{equation*}

Then we have
\begin{equation*}
    M_{p,p}(r,\sigma)\leq D_p(\tau=\bigsqcup\theta)^p\prod_{j=1}^n\left(\sum_{\theta}\|f_{j,\theta}\|_{L^p}^2 \right)^{p/2n}=D_p(\tau=\bigsqcup\theta)^pM_{p,p}(R,R^{1/2})
\end{equation*}
We note here that $D_p(\tau=\bigsqcup\theta)=D_p(R/\sigma^2)$.
Hence combining, we have
\begin{equation*}
    M_{p,2}(1,1)\lesssim R^{O(\delta)}M_{p,2}(r^2,r)^{1/2}D_p(R/\sigma^2)^{p/2}M_{p,p}(R,R^{1/2})^{1/2}
\end{equation*}
Hence if we choose $r=R^\delta, \delta=2^{-s}$, then we get
\begin{equation*}
    D_{p,2}(1,1)\lesssim R^{O(\delta)}D_p(R^{1-2\delta})M_{p,2}(r^2, r)^{1/2}M_{p,p}(R, R^{1/2})^{1/2}
\end{equation*}
And for the $M_{p,2}(r^2, r)^{1/2}$, like commented above, we can repeat the process and will get
\begin{equation*}
    M_{p,2}(r^2, r)^{1/2}\lesssim D_p(R^{1-4\delta})M_{p,2}(r^4, r^2)^{1/4}M_{p,p}(R,R^{1/2})^{1/4}
\end{equation*}
Hence combining, we have
\begin{equation*}
    M_{p,2}(1,1)\lesssim R^{O(\delta)}D_p(R^{1-2\delta})^{p/2}D_p(R^{1-4\delta})^{p/4}M_{p,2}(r^2,r)^{1/4}M_{p,p}(R,R^{1/2})^{3/4}
\end{equation*}
We can simply repeat this process to further break down $M_{p,2}(r^2, r)$. We then eventually get 
\begin{equation*}
    M_{p,2}(1,1)\lesssim R^{O(\delta)}D_p(R^{1-2\delta})^{p/2}D_p(R^{1-4\delta})^{p/4}...D_p(R^{1/2})^{p/2^{-s+1}}M_{p,p}(R,R^{1/2})
\end{equation*}
So eventually, we interpret this in our multilinear decoupling constant and that translates to
\begin{equation*}
    MD_{p}(R)\lesssim R^{O(\delta)}D_p(R^{1-2\delta})^{1/2}D_p(R^{1-4\delta})^{1/4}...D_p(R^{1/2})^{1/2^{-s+1}}
\end{equation*}
Now we wish to bound this term by $R^\epsilon$ and recall
\begin{equation*}
    D_{p,n}(R)\lesssim K^{O(1)}MD_{p,n}(R)+D_{p,n-1}(K^2)D_{p,n}(R/K^2)
\end{equation*}
We now illustrate how we bound the above $MD$ term by $R^\epsilon$ in Lecture 13.
